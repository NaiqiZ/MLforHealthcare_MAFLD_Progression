{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c0a7b9",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf76131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/nobackup/users/ericason/mlhc-final-project/clean_data/nafl/combined.large.nafl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a62441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X and Y datasets\n",
    "\n",
    "data = data.drop(columns='DaysUntilFirstProgression')\n",
    "# data = data.drop(columns='Outcome')\n",
    "data = data.drop(columns='Censored')\n",
    "\n",
    "Y = data[['StudyID', 'Outcome']]\n",
    "# Y = data[['StudyID', 'DaysUntilFirstProgression']]\n",
    "X = data.drop(columns='Outcome')\n",
    "X = X.drop(columns=['mean_BMI_category', 'last_BMI_category'])\n",
    "\n",
    "\n",
    "X = X.set_index('StudyID')\n",
    "Y = Y.set_index('StudyID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype(int)        # from True/False → 1/0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb55b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is enabled\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # need to define device since python can use both cpu and gpu\n",
    "print(f\"Using {device} device\")\n",
    "print(f\"Shape of X: {X.shape}. Shape of Y: {Y.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bmi, lab, age \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c009bc7",
   "metadata": {},
   "source": [
    "# establish the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc84d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reweighted\n",
    "class MAFLDDataset(Dataset):\n",
    "    def __init__(self, X, y, w):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.w = torch.tensor(w, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.w[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define by subclassing nn.Module and initialize the neural network layers in __init__.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # inherit init from parent class\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of NeuralNetwork, move to device, print its structure\n",
    "model = NeuralNetwork().to(device)\n",
    "# print(model)\n",
    "\n",
    "# define loss function and optimizer\n",
    "# loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.BCELoss() # if using BCELoss, do not run the sigmoid layer in the forward step!\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) # start with this baseline learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286913e9",
   "metadata": {},
   "source": [
    "# train model on train/test split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#reweight\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Identify columns to scale\n",
    "cols_bmi_age = [col for col in X.columns if 'bmi' in col.lower() or 'age' in col.lower()]\n",
    "cols_lab = [col for col in X.columns if col.startswith(\"Lab_\") and pd.api.types.is_numeric_dtype(X[col])]\n",
    "cols_to_scale = cols_bmi_age + cols_lab\n",
    "\n",
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train_np = X_train_scaled.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.float32) \n",
    "X_test_np = X_test_scaled.values.astype(np.float32)\n",
    "y_test_np = y_test.values.astype(np.float32)\n",
    "\n",
    "# Compute class weights\n",
    "counts = Counter(y_train_np.ravel())\n",
    "total = sum(counts.values())\n",
    "#class_weights = {cls: total/count for cls, count in counts.items()}\n",
    "class_weights = {\n",
    "    0.0: 1.0,   # majority class\n",
    "    1.0: 50.0   # minority class – give 50x more importance\n",
    "}\n",
    "\n",
    "sample_weights = np.array([class_weights[y] for y in y_train_np.ravel()], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_torch = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "Y_torch = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "W_torch = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32).to(device)\n",
    "Y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ae73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_data = MAFLDDataset(X_torch, Y_torch, W_torch)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "#early stopping\n",
    "\n",
    "model = SimpleNN(X_torch.shape[1]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(reduction='none')  # We'll weight manually\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "num_epochs = 30\n",
    "patience = 5  # early stopping patience\n",
    "best_auc = 0\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_X, batch_y, batch_w in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device).squeeze() \n",
    "        batch_w = batch_w.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X).squeeze()\n",
    "        loss = (loss_fn(outputs, batch_y) * batch_w).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(X_test_tensor).squeeze()\n",
    "        val_probs = torch.sigmoid(val_preds)\n",
    "        val_auc = roc_auc_score(y_test_np.ravel(), val_probs.cpu().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reweight\n",
    "# original model\n",
    "# num_epochs = 20\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "#     for batch_X, batch_y, batch_w in train_data:  # train_data must return sample weights too\n",
    "#         # Move to device\n",
    "#         batch_X = torch.tensor(batch_X).to(device)\n",
    "#         batch_y = torch.tensor(batch_y).to(device)\n",
    "#         batch_w = torch.tensor(batch_w).to(device)\n",
    "\n",
    "#         # Zero gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(batch_X)\n",
    "\n",
    "#         # Compute weighted loss (e.g., Binary Cross Entropy)\n",
    "#         loss = (loss_fn(outputs, batch_y) * batch_w).mean()\n",
    "\n",
    "#         # Backward and optimize\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f\"Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7692c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reweight\n",
    "# Run model on test data\n",
    "X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32).values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Run model and evaluate\n",
    "Y_hat_test = model(X_test_tensor)\n",
    "Y_hat_probs = torch.sigmoid(Y_hat_test)\n",
    "Y_pred_binary = (Y_hat_probs > 0.2).float()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test.values.ravel(), Y_pred_binary.cpu().detach().numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Y_pred_binary.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efaafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_np, Y_hat_probs.cpu().detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878419b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17145c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tweaking model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ebbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # inherit init from parent class\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1), # no activation follows this layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = self.linear_relu_stack(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding dropout, switching to LeakyReLU, adding batchnorm layers\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # inherit init from parent class\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = self.linear_relu_stack(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff316644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempting skip connections\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + self.block(x))  # skip connection\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, 256)\n",
    "\n",
    "        self.resblock1 = ResidualBlock(256)\n",
    "        self.resblock2 = ResidualBlock(256)\n",
    "        self.resblock3 = ResidualBlock(256)\n",
    "\n",
    "        self.output_layer = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8953c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an experiment manager that can test run the various edits we want to make\n",
    "from itertools import product\n",
    "\n",
    "search_space = {\n",
    "    \"hidden_sizes\": [[512, 128], [1024, 512, 128]],\n",
    "    \"activation\": [\"relu\", \"leaky_relu\"],\n",
    "    \"dropout\": [0.0, 0.2],\n",
    "    \"use_batchnorm\": [True, False],\n",
    "    \"learning_rate\": [1e-3, 1e-4]\n",
    "}\n",
    "\n",
    "# Create list of all combinations\n",
    "all_configs = [dict(zip(search_space.keys(), values)) for values in product(*search_space.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def get_activation(name):\n",
    "    return {\n",
    "        \"relu\": nn.ReLU(),\n",
    "        \"leaky_relu\": nn.LeakyReLU(0.01),\n",
    "    }[name]\n",
    "\n",
    "class FlexibleNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes, activation, dropout, use_batchnorm):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last_dim = input_dim\n",
    "        for h in hidden_sizes: # for each layer, construct linear + batchnorm + dropout\n",
    "            layers.append(nn.Linear(last_dim, h))\n",
    "            if use_batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(get_activation(activation))\n",
    "            if dropout > 0.0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            last_dim = h\n",
    "        layers.append(nn.Linear(last_dim, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c63f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop and evaluator\n",
    "def train_model(model, train_loader, val_loader, lr, device=\"cpu\", epochs=10):\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            loss = loss_fn(model(x).squeeze(), y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                val_loss += loss_fn(model(x).squeeze(), y).item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "    return val_losses[-1]  # return final validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2110ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments\n",
    "def run_experiments(X_train, y_train, X_val, y_val):\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    results = []\n",
    "    for config in all_configs:\n",
    "        print(f\"Running config: {config}\")\n",
    "        model = FlexibleNetwork(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_sizes=config[\"hidden_sizes\"],\n",
    "            activation=config[\"activation\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            use_batchnorm=config[\"use_batchnorm\"]\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(MAFLDDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(MAFLDDataset(X_val, y_val), batch_size=64)\n",
    "\n",
    "        val_loss = train_model(model, train_loader, val_loader, lr=config[\"learning_rate\"])\n",
    "        results.append((config, val_loss))\n",
    "        print(f\"Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "    return sorted(results, key=lambda x: x[1])  # sorted by val loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b74e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_torch, Y_torch, test_size=0.3, random_state=42)\n",
    "\n",
    "train_dataset = MAFLDDataset(X_train, y_train)\n",
    "train_data = DataLoader(train_dataset, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b450ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e071dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-env)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
